import Image from 'next/image';
import embeddings from './embeddings.jpg';
import BackgoroundAI from './opengraph-image.jpg';
import BlogImage from '@/components/Writing/Post-Components/container-image.js';
import MediaContainer from '@/components/Writing/Post-Components/container-media.js';

export const metadata = {
  title: 'The Rise of AI in Software Development',
  date: '2024-08-13',
  readTime: 'About 10 mins',
  description: 'Thoughts on AI in modern workflows.',
  tags: ['AI'],
  isPublished: true,
  isFeatured: false,
  type: 'post',
  image: '',
  excerpt: '',
};

<BlogImage src={BackgoroundAI} alt='The crazy state of AI' />

# Understanding AI

I wanted to better understand how AI models are created. Not to become an expert, but to gain an appreciation for the abstractions I use every day.

This post will highlight what I’ve learned so far. It’s written for other engineers who are new to topics like neural networks, deep learning, and transformers.

## Machine Learning

Software is _deterministic_. Given some input, if you run the program again, you will get the same output. A developer has explicitly written code to handle each case.

Most AI models[¹](#footnotes) are not this way — they are _probabilistic_. Developers don’t have to explicitly program the instructions.

[Machine learning](http://www.r2d3.us/visual-intro-to-machine-learning-part-1/) teaches software to recognize patterns from data. Given some input, you might _not_ get the same output[²](#footnotes). AI models like GPT (from OpenAI), Claude (from Anthropic), and Gemini (from Google) are “trained” on a large chunk of internet documents. These models learn patterns during training.

Then, there’s an API or chat interface where you can talk to the model. Based on some input, it can predict and generate sentences, images, or audio as output. You can think about machine learning as a subset of the broader AI category.

## Neural Networks

AI models are built on [neural networks](https://www.youtube.com/watch?v=aircAruvnKk&list=PLZHQObOWTQDNU6R1_67000Dx_ZCJB-3pi) — think of them as a giant web of decision-making pathways that learn from examples. Neural networks can be used for anything, but I'll focus on language models.

These networks consist of layers of interconnected _neurons_ that process information:

1.  An **input layer** where data enters the system. Input is converted into a numerical representation of words or _tokens_ (more on tokens later).
2.  Many **hidden layers** that create an understanding of patterns in the system. Neurons inside the layer apply _weights_ (also known as **parameters**) to the input data and pass the result through an **activation function**[³](#footnotes). This function outputs a value, often between 0 and 1, representing the neuron's level of activation.
3.  An **output layer** which produces the final result, such as predicting the next word in a sentence. The outputs at this stage are often referred to as _logits_, which are raw scores that get transformed into probabilities.

For example, if the input was “San”, there is likely an activation close to 1 for the next word of “Francisco”. A unrelated word like “kitten” would be close to 0.

A big takeaway for me is: it’s just math. You can build a neural network [from first principles](https://www.youtube.com/playlist?list=PLAqhIrjkxbuWI23v9cThsA9GvCAUhRvKZ) using linear algebra, calculus, and statistics. You likely _won’t_ do this when there’s helpful abstractions like PyTorch, but it’s helpful for me to demystify what is happening under the hood.
